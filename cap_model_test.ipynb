{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i9zDh5jRMAMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import output  # For exposing the server in Colab\n",
        "from werkzeug.middleware.proxy_fix import ProxyFix\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "app.template_folder = \"/content/templates\"\n",
        "\n",
        "# Load ResNet50 model and adapt for binary classification\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')  # Load pre-trained model\n",
        "# Add a custom dense layer for binary classification\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define labels\n",
        "LABELS = [\"non_damaged\", \"damaged\"]\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "    # Render the upload page\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded image\n",
        "    imagefile = request.files['imagefile']\n",
        "    if not imagefile:\n",
        "        return \"No image file uploaded!\", 400\n",
        "\n",
        "    # Save the uploaded image\n",
        "    upload_folder = \"/content/uploads\"\n",
        "    os.makedirs(upload_folder, exist_ok=True)  # Ensure the folder exists\n",
        "    image_path = os.path.join(upload_folder, imagefile.filename)\n",
        "    imagefile.save(image_path)\n",
        "\n",
        "    # Preprocess the image\n",
        "    image = load_img(image_path, target_size=(224, 224))  # Resize image to ResNet50 input size\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))  # Reshape for the model\n",
        "    image = preprocess_input(image)  # Preprocess for ResNet50\n",
        "\n",
        "    # Make prediction\n",
        "    yhat = model.predict(image)\n",
        "    confidence = yhat[0][0]  # Model's confidence (probability for class \"damaged\")\n",
        "    label_index = int(confidence > 0.5)  # Threshold of 0.5 for binary classification\n",
        "    classification = LABELS[label_index]  # Map prediction to label\n",
        "\n",
        "    # Format prediction with percentage\n",
        "    confidence_percentage = confidence_percentage = confidence * 100 if classification == \"damaged\" else (1 - confidence) * 100\n",
        "\n",
        "\n",
        "    formatted_prediction = f\"{classification} ({confidence_percentage:.2f}%)\"\n",
        "\n",
        "    #  Render the result\n",
        "    return render_template('index.html', prediction=formatted_prediction)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Fix for running behind a proxy (like in Colab)\n",
        "    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)\n",
        "\n",
        "    # Expose the server in Colab\n",
        "    port = 5000\n",
        "    output.serve_kernel_port_as_iframe(port)\n",
        "    app.run(host='0.0.0.0', port=port)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "4pXp5aR4-mTO",
        "outputId": "0dc15404-0fc7-415e-f103-c077e862d6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(5000, \"/\", \"100%\", \"400\", false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [14/Feb/2025 15:32:41] \"GET /?authuser=0 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [14/Feb/2025 15:32:55] \"POST /?authuser=0 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [14/Feb/2025 15:33:16] \"POST /?authuser=0 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [14/Feb/2025 15:33:32] \"POST /?authuser=0 HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-ndiVRc-m_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}